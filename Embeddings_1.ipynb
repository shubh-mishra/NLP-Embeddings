{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Embeddings_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpP_My4Whqzl"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNGRU"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nY064jFjs3X",
        "outputId": "6da820e1-fafb-46ef-e9c7-8a72ca87e621"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXSlZATshqzq",
        "outputId": "ebed39bd-8c86-4270-a4d2-046e7f35defb"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "print(\"Train shape : \",train_df.shape)\n",
        "print(\"Test shape : \",test_df.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (1306122, 3)\n",
            "Test shape :  (375806, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8jD9ESThqzr"
      },
      "source": [
        "Next steps are as follows:\n",
        "\n",
        "Split the training dataset into train and val sample. Cross validation is a time consuming process and so let us do simple train val split.\n",
        "Fill up the missing values in the text column with 'na'\n",
        "Tokenize the text column and convert them to vector sequences\n",
        "Pad the sequence as needed - if the number of words in the text is greater than 'max_len' trunacate them to 'max_len' or if the number of words in the text is lesser than 'max_len' add zeros for remaining values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3okhyB7hqzs"
      },
      "source": [
        "## split to train and val\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
        "\n",
        "## some config values \n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use\n",
        "\n",
        "## fill up the missing values\n",
        "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
        "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
        "test_X = test_df[\"question_text\"].fillna(\"_na_\").values\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
        "\n",
        "## Get the target values\n",
        "train_y = train_df['target'].values\n",
        "val_y = val_df['target'].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y16atelchqzs"
      },
      "source": [
        "Without Pretrained Embeddings:\n",
        "\n",
        "Now that we are done with all the necessary preprocessing steps, we can first train a Bidirectional GRU model. We will not use any pre-trained word embeddings for this model and the embeddings will be learnt from scratch. Please check out the model summary for the details of the layers used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HofGqtB8hqzt",
        "outputId": "00967c6b-5627-44c4-e14b-7518420f7c7f"
      },
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0Z-dTPhqzt"
      },
      "source": [
        "Train the model using train sample and monitor the metric on the valid sample. This is just a sample model running for 2 epochs. Changing the epochs, batch_size and model parameters might give us a better model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH9EHX1Shqzt",
        "outputId": "54634a0c-3385-4fd3-ef9a-11fce2b9a0e4"
      },
      "source": [
        "## Train the model \n",
        "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2296/2296 [==============================] - 453s 184ms/step - loss: 0.1564 - accuracy: 0.9462 - val_loss: 0.1078 - val_accuracy: 0.9564\n",
            "Epoch 2/2\n",
            "2296/2296 [==============================] - 421s 183ms/step - loss: 0.1005 - accuracy: 0.9582 - val_loss: 0.1060 - val_accuracy: 0.9571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f023f831710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVL-Ro-thqzu"
      },
      "source": [
        "Now let us get the validation sample predictions and also get the best threshold for F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qnRGp7Whqzu",
        "outputId": "8b46c7f0-8604-4bf4-f0e8-57de85fd9bf6"
      },
      "source": [
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 5s 38ms/step\n",
            "F1 score at threshold 0.1 is 0.5878599544230371\n",
            "F1 score at threshold 0.11 is 0.5958095238095238\n",
            "F1 score at threshold 0.12 is 0.6026117789500995\n",
            "F1 score at threshold 0.13 is 0.6094515289237966\n",
            "F1 score at threshold 0.14 is 0.6161593453531766\n",
            "F1 score at threshold 0.15 is 0.6212100425298395\n",
            "F1 score at threshold 0.16 is 0.6264936997256706\n",
            "F1 score at threshold 0.17 is 0.6296785141887433\n",
            "F1 score at threshold 0.18 is 0.6324288171221096\n",
            "F1 score at threshold 0.19 is 0.635914811229429\n",
            "F1 score at threshold 0.2 is 0.6387676004513565\n",
            "F1 score at threshold 0.21 is 0.6412714179289793\n",
            "F1 score at threshold 0.22 is 0.6439127375087965\n",
            "F1 score at threshold 0.23 is 0.6454600977198697\n",
            "F1 score at threshold 0.24 is 0.6469346785401761\n",
            "F1 score at threshold 0.25 is 0.6485613010842369\n",
            "F1 score at threshold 0.26 is 0.6502135738016137\n",
            "F1 score at threshold 0.27 is 0.6507064782724608\n",
            "F1 score at threshold 0.28 is 0.6508346795907377\n",
            "F1 score at threshold 0.29 is 0.6514391626689925\n",
            "F1 score at threshold 0.3 is 0.6539542573711766\n",
            "F1 score at threshold 0.31 is 0.6543368057489833\n",
            "F1 score at threshold 0.32 is 0.6558262533055759\n",
            "F1 score at threshold 0.33 is 0.6563281072483528\n",
            "F1 score at threshold 0.34 is 0.6560421921577619\n",
            "F1 score at threshold 0.35 is 0.6543224163869923\n",
            "F1 score at threshold 0.36 is 0.6533971515293019\n",
            "F1 score at threshold 0.37 is 0.653646447958461\n",
            "F1 score at threshold 0.38 is 0.6517175572519085\n",
            "F1 score at threshold 0.39 is 0.6515270164447925\n",
            "F1 score at threshold 0.4 is 0.6501762489364288\n",
            "F1 score at threshold 0.41 is 0.6474193943851907\n",
            "F1 score at threshold 0.42 is 0.6453808551451025\n",
            "F1 score at threshold 0.43 is 0.6424870466321243\n",
            "F1 score at threshold 0.44 is 0.6403425908432521\n",
            "F1 score at threshold 0.45 is 0.6391202085054987\n",
            "F1 score at threshold 0.46 is 0.6372977138453635\n",
            "F1 score at threshold 0.47 is 0.6356388150644973\n",
            "F1 score at threshold 0.48 is 0.632291119285339\n",
            "F1 score at threshold 0.49 is 0.6286701208981003\n",
            "F1 score at threshold 0.5 is 0.623030303030303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sr-CyBChqzu"
      },
      "source": [
        "Now let us get the test set predictions as well and save them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHPTyxeZhqzv",
        "outputId": "adbf83a8-cd08-4e84-e5f6-d5af44328bc8"
      },
      "source": [
        "pred_noemb_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "367/367 [==============================] - 14s 37ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBuImBUXhqzv"
      },
      "source": [
        "Now that our model building is done, it might be a good idea to clean up some memory before we go to the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDIqV-1phqzw"
      },
      "source": [
        "del model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN7_KSVkhqzw"
      },
      "source": [
        "So we got some baseline GRU model without pre-trained embeddings. Now let us use the provided embeddings and rebuild the model again to see the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axcjy8LHhqzw"
      },
      "source": [
        "We have four different types of embeddings.\n",
        "\n",
        "GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
        "glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
        "paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
        "wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html\n",
        "\n",
        "A very good explanation for different types of embeddings are given in this kernel. Please refer the same for more details..\n",
        "\n",
        "Glove Embeddings:\n",
        "\n",
        "In this section, let us use the Glove embeddings and rebuild the GRU model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tG5WIuwBquX",
        "outputId": "6fd9d5c6-40cc-469b-977d-11d1f1049a0e"
      },
      "source": [
        "!unzip drive/My\\ Drive/embeddings.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/embeddings.zip\n",
            "   creating: GoogleNews-vectors-negative300/\n",
            "   creating: glove.840B.300d/\n",
            "   creating: paragram_300_sl999/\n",
            "   creating: wiki-news-300d-1M/\n",
            "  inflating: glove.840B.300d/glove.840B.300d.txt  \n",
            "  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n",
            "  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n",
            "  inflating: paragram_300_sl999/README.txt  \n",
            "  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdGLmcjuFFEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1gJDPQPhqzx",
        "outputId": "172dcb48-83c3-4be1-f778-40d978067526"
      },
      "source": [
        "EMBEDDING_FILE = '/content/glove.840B.300d/glove.840B.300d.txt'\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "        \n",
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqBmVxSBhqzx",
        "outputId": "da13d2a1-4c93-4e2f-bf7e-855b01a0fc33"
      },
      "source": [
        "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2296/2296 [==============================] - 430s 186ms/step - loss: 0.1326 - accuracy: 0.9499 - val_loss: 0.1010 - val_accuracy: 0.9595\n",
            "Epoch 2/2\n",
            "2296/2296 [==============================] - 430s 187ms/step - loss: 0.0938 - accuracy: 0.9628 - val_loss: 0.1001 - val_accuracy: 0.9596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00b85936d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-Mz_23Ohqzx",
        "outputId": "71a552ac-7af5-4ca1-8e7e-60a4c3654e2c"
      },
      "source": [
        "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 5s 40ms/step\n",
            "F1 score at threshold 0.1 is 0.5890056588520614\n",
            "F1 score at threshold 0.11 is 0.5980675530597076\n",
            "F1 score at threshold 0.12 is 0.6068354430379748\n",
            "F1 score at threshold 0.13 is 0.6154110767113864\n",
            "F1 score at threshold 0.14 is 0.6222183283686701\n",
            "F1 score at threshold 0.15 is 0.6277079433003477\n",
            "F1 score at threshold 0.16 is 0.6328666576050019\n",
            "F1 score at threshold 0.17 is 0.6374850409647428\n",
            "F1 score at threshold 0.18 is 0.642763772175537\n",
            "F1 score at threshold 0.19 is 0.6466578299564477\n",
            "F1 score at threshold 0.2 is 0.6510556621880998\n",
            "F1 score at threshold 0.21 is 0.6548440384802253\n",
            "F1 score at threshold 0.22 is 0.6590271971671667\n",
            "F1 score at threshold 0.23 is 0.6615576013933815\n",
            "F1 score at threshold 0.24 is 0.662945642882285\n",
            "F1 score at threshold 0.25 is 0.6665311308767471\n",
            "F1 score at threshold 0.26 is 0.6682063125481139\n",
            "F1 score at threshold 0.27 is 0.6697461981626616\n",
            "F1 score at threshold 0.28 is 0.6708237266820373\n",
            "F1 score at threshold 0.29 is 0.673401385730153\n",
            "F1 score at threshold 0.3 is 0.6748905265406386\n",
            "F1 score at threshold 0.31 is 0.6753666954270924\n",
            "F1 score at threshold 0.32 is 0.6760010896213565\n",
            "F1 score at threshold 0.33 is 0.6773039889958735\n",
            "F1 score at threshold 0.34 is 0.6783216783216784\n",
            "F1 score at threshold 0.35 is 0.6785314528766511\n",
            "F1 score at threshold 0.36 is 0.6784767277856135\n",
            "F1 score at threshold 0.37 is 0.677099931709538\n",
            "F1 score at threshold 0.38 is 0.6768807023584094\n",
            "F1 score at threshold 0.39 is 0.6767717674284061\n",
            "F1 score at threshold 0.4 is 0.6770092149772542\n",
            "F1 score at threshold 0.41 is 0.676417033773862\n",
            "F1 score at threshold 0.42 is 0.674564625044426\n",
            "F1 score at threshold 0.43 is 0.6741519350215002\n",
            "F1 score at threshold 0.44 is 0.6732553935157285\n",
            "F1 score at threshold 0.45 is 0.6714494163424124\n",
            "F1 score at threshold 0.46 is 0.6696549183347661\n",
            "F1 score at threshold 0.47 is 0.6689381737083385\n",
            "F1 score at threshold 0.48 is 0.6679584948118514\n",
            "F1 score at threshold 0.49 is 0.666036308623298\n",
            "F1 score at threshold 0.5 is 0.6643787734350175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHwBycYqhqzy",
        "outputId": "2bb13694-976e-4fff-a482-379bcbd02a3b"
      },
      "source": [
        "pred_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "367/367 [==============================] - 15s 40ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9XWk08uhqzy"
      },
      "source": [
        "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dZkPjH0hqzy"
      },
      "source": [
        "Wiki News FastText Embeddings:\n",
        "\n",
        "Now let us use the FastText embeddings trained on Wiki News corpus in place of Glove embeddings and rebuild the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNKWDHwshqzy",
        "outputId": "77889ddf-60ff-460f-fdbb-d988572e2f5c"
      },
      "source": [
        "EMBEDDING_FILE = '/content/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\") if len(o)>100)\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "        \n",
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elfEOsB0hqzy",
        "outputId": "68e56cc0-c43e-4815-df5e-9cf917a8f29b"
      },
      "source": [
        "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2296/2296 [==============================] - 436s 189ms/step - loss: 0.1390 - accuracy: 0.9483 - val_loss: 0.1025 - val_accuracy: 0.9591\n",
            "Epoch 2/2\n",
            "2296/2296 [==============================] - 440s 192ms/step - loss: 0.0923 - accuracy: 0.9632 - val_loss: 0.1035 - val_accuracy: 0.9597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00c8eaf550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkJ_vHqZhqzz",
        "outputId": "ada008cb-80fe-42a0-e47e-994cfc6dae36"
      },
      "source": [
        "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 6s 44ms/step\n",
            "F1 score at threshold 0.1 is 0.6250792213671345\n",
            "F1 score at threshold 0.11 is 0.6310091148845602\n",
            "F1 score at threshold 0.12 is 0.637918004912148\n",
            "F1 score at threshold 0.13 is 0.643629547748354\n",
            "F1 score at threshold 0.14 is 0.6486354537909486\n",
            "F1 score at threshold 0.15 is 0.6532394086714951\n",
            "F1 score at threshold 0.16 is 0.6560772092088067\n",
            "F1 score at threshold 0.17 is 0.6592634099128929\n",
            "F1 score at threshold 0.18 is 0.6610256939428336\n",
            "F1 score at threshold 0.19 is 0.6635303956928545\n",
            "F1 score at threshold 0.2 is 0.6653616210782498\n",
            "F1 score at threshold 0.21 is 0.665881597259394\n",
            "F1 score at threshold 0.22 is 0.6659088448630508\n",
            "F1 score at threshold 0.23 is 0.6663386902809664\n",
            "F1 score at threshold 0.24 is 0.6668877099911582\n",
            "F1 score at threshold 0.25 is 0.6678571428571428\n",
            "F1 score at threshold 0.26 is 0.6682833295736522\n",
            "F1 score at threshold 0.27 is 0.6693263421862532\n",
            "F1 score at threshold 0.28 is 0.670040835106689\n",
            "F1 score at threshold 0.29 is 0.6697247706422018\n",
            "F1 score at threshold 0.3 is 0.6683092807696822\n",
            "F1 score at threshold 0.31 is 0.6683244523386619\n",
            "F1 score at threshold 0.32 is 0.6683375104427737\n",
            "F1 score at threshold 0.33 is 0.6670681763430499\n",
            "F1 score at threshold 0.34 is 0.6666262062268616\n",
            "F1 score at threshold 0.35 is 0.6651553213651125\n",
            "F1 score at threshold 0.36 is 0.6641500092827527\n",
            "F1 score at threshold 0.37 is 0.6620061169714749\n",
            "F1 score at threshold 0.38 is 0.6615897790924539\n",
            "F1 score at threshold 0.39 is 0.6615062496034515\n",
            "F1 score at threshold 0.4 is 0.6601010423994372\n",
            "F1 score at threshold 0.41 is 0.6579015210105698\n",
            "F1 score at threshold 0.42 is 0.6577320929022185\n",
            "F1 score at threshold 0.43 is 0.6539699218493465\n",
            "F1 score at threshold 0.44 is 0.651646676827248\n",
            "F1 score at threshold 0.45 is 0.6488799732530925\n",
            "F1 score at threshold 0.46 is 0.6461351843116112\n",
            "F1 score at threshold 0.47 is 0.6433423913043479\n",
            "F1 score at threshold 0.48 is 0.639868520167089\n",
            "F1 score at threshold 0.49 is 0.6367279259361613\n",
            "F1 score at threshold 0.5 is 0.6325477618184353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xRjmCgHhqzz",
        "outputId": "e7540c07-832d-4bb1-f45b-01dab72a0810"
      },
      "source": [
        "pred_fasttext_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "367/367 [==============================] - 16s 43ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eskCv7dJhqzz"
      },
      "source": [
        "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYqolWCmhqzz"
      },
      "source": [
        "Paragram Embeddings:\n",
        "\n",
        "In this section, we can use the paragram embeddings and build the model and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDftdp8Ehqzz",
        "outputId": "14867dc2-93b3-4a77-a539-24a716bb10af"
      },
      "source": [
        "EMBEDDING_FILE = '/content/paragram_300_sl999/paragram_300_sl999.txt'\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "        \n",
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CXH7pwphqz0",
        "outputId": "d81e5f42-525c-4a27-ea46-07e6db15271e"
      },
      "source": [
        "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2296/2296 [==============================] - 428s 186ms/step - loss: 0.1375 - accuracy: 0.9468 - val_loss: 0.1025 - val_accuracy: 0.9589\n",
            "Epoch 2/2\n",
            "2296/2296 [==============================] - 425s 185ms/step - loss: 0.0954 - accuracy: 0.9620 - val_loss: 0.1017 - val_accuracy: 0.9587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00c5bf2b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXBLlHzYhqz0",
        "outputId": "952a4f40-07c4-4350-9485-52e5b0abfccb"
      },
      "source": [
        "pred_paragram_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_paragram_val_y>thresh).astype(int))))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 5s 40ms/step\n",
            "F1 score at threshold 0.1 is 0.5789034896184843\n",
            "F1 score at threshold 0.11 is 0.5883069922398734\n",
            "F1 score at threshold 0.12 is 0.5965188561956071\n",
            "F1 score at threshold 0.13 is 0.6034919028340081\n",
            "F1 score at threshold 0.14 is 0.6107053870607441\n",
            "F1 score at threshold 0.15 is 0.6169162918649841\n",
            "F1 score at threshold 0.16 is 0.6226264418811003\n",
            "F1 score at threshold 0.17 is 0.626675060706898\n",
            "F1 score at threshold 0.18 is 0.6311180039228208\n",
            "F1 score at threshold 0.19 is 0.6353897303287772\n",
            "F1 score at threshold 0.2 is 0.6396404831008332\n",
            "F1 score at threshold 0.21 is 0.6432260815997726\n",
            "F1 score at threshold 0.22 is 0.6464016876827924\n",
            "F1 score at threshold 0.23 is 0.6499417701863355\n",
            "F1 score at threshold 0.24 is 0.6528009418228196\n",
            "F1 score at threshold 0.25 is 0.6550235673530141\n",
            "F1 score at threshold 0.26 is 0.6572115866492932\n",
            "F1 score at threshold 0.27 is 0.6600800526929117\n",
            "F1 score at threshold 0.28 is 0.6622340425531914\n",
            "F1 score at threshold 0.29 is 0.6643259152166054\n",
            "F1 score at threshold 0.3 is 0.6654147104851331\n",
            "F1 score at threshold 0.31 is 0.66635046113307\n",
            "F1 score at threshold 0.32 is 0.6671987230646449\n",
            "F1 score at threshold 0.33 is 0.6679561573178594\n",
            "F1 score at threshold 0.34 is 0.6699934909958776\n",
            "F1 score at threshold 0.35 is 0.6710843373493977\n",
            "F1 score at threshold 0.36 is 0.6724842593615377\n",
            "F1 score at threshold 0.37 is 0.6733203233900196\n",
            "F1 score at threshold 0.38 is 0.6746241765666348\n",
            "F1 score at threshold 0.39 is 0.675035501278046\n",
            "F1 score at threshold 0.4 is 0.6764925159144348\n",
            "F1 score at threshold 0.41 is 0.67533969355305\n",
            "F1 score at threshold 0.42 is 0.6740234717113329\n",
            "F1 score at threshold 0.43 is 0.6736209335219236\n",
            "F1 score at threshold 0.44 is 0.6730895034195659\n",
            "F1 score at threshold 0.45 is 0.6701884980189698\n",
            "F1 score at threshold 0.46 is 0.6687257751937984\n",
            "F1 score at threshold 0.47 is 0.6676866585067319\n",
            "F1 score at threshold 0.48 is 0.6655157531290462\n",
            "F1 score at threshold 0.49 is 0.6638895797065407\n",
            "F1 score at threshold 0.5 is 0.6611798705786267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNY1hfZ6hqz0",
        "outputId": "06aa8777-ba29-4236-cc24-262767e42b32"
      },
      "source": [
        "pred_paragram_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "367/367 [==============================] - 15s 40ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3cK0gMuhqz0"
      },
      "source": [
        "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SguL1904fcG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JXdGG0Shqz0"
      },
      "source": [
        "Observations:\n",
        "\n",
        "Overall pretrained embeddings seem to give better results comapred to non-pretrained model.\n",
        "The performance of the different pretrained embeddings are almost similar.\n",
        "Final Blend:\n",
        "\n",
        "Though the results of the models with different pre-trained embeddings are similar, there is a good chance that they might capture different type of information from the data. So let us do a blend of these three models by averaging their predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08pUt3szhqz1",
        "outputId": "82ce111e-a699-4cab-e3ed-72efd8d78a82"
      },
      "source": [
        "pred_val_y = 0.33*pred_glove_val_y + 0.33*pred_fasttext_val_y + 0.34*pred_paragram_val_y \n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score at threshold 0.1 is 0.5984329490913565\n",
            "F1 score at threshold 0.11 is 0.6074950690335306\n",
            "F1 score at threshold 0.12 is 0.6144501005261581\n",
            "F1 score at threshold 0.13 is 0.6222183436600052\n",
            "F1 score at threshold 0.14 is 0.6299296715036055\n",
            "F1 score at threshold 0.15 is 0.635655403569164\n",
            "F1 score at threshold 0.16 is 0.6410268206284215\n",
            "F1 score at threshold 0.17 is 0.6470945724837549\n",
            "F1 score at threshold 0.18 is 0.6515734016801936\n",
            "F1 score at threshold 0.19 is 0.6558798035249928\n",
            "F1 score at threshold 0.2 is 0.6603598771151314\n",
            "F1 score at threshold 0.21 is 0.6643273697736484\n",
            "F1 score at threshold 0.22 is 0.6679337768218877\n",
            "F1 score at threshold 0.23 is 0.6707848101265822\n",
            "F1 score at threshold 0.24 is 0.6718158567774937\n",
            "F1 score at threshold 0.25 is 0.6726680117957473\n",
            "F1 score at threshold 0.26 is 0.6747214812490193\n",
            "F1 score at threshold 0.27 is 0.6757070493879274\n",
            "F1 score at threshold 0.28 is 0.6772955102911379\n",
            "F1 score at threshold 0.29 is 0.6795196294900103\n",
            "F1 score at threshold 0.3 is 0.6796306355241716\n",
            "F1 score at threshold 0.31 is 0.68163601427395\n",
            "F1 score at threshold 0.32 is 0.6830079858030169\n",
            "F1 score at threshold 0.33 is 0.6831234256926952\n",
            "F1 score at threshold 0.34 is 0.6840379832692742\n",
            "F1 score at threshold 0.35 is 0.6843937232524964\n",
            "F1 score at threshold 0.36 is 0.6832362608846086\n",
            "F1 score at threshold 0.37 is 0.6829580496887182\n",
            "F1 score at threshold 0.38 is 0.683027306967985\n",
            "F1 score at threshold 0.39 is 0.6824396623469267\n",
            "F1 score at threshold 0.4 is 0.6815072602904116\n",
            "F1 score at threshold 0.41 is 0.6803075246685635\n",
            "F1 score at threshold 0.42 is 0.6783747399339126\n",
            "F1 score at threshold 0.43 is 0.6766230560355468\n",
            "F1 score at threshold 0.44 is 0.6743896362730443\n",
            "F1 score at threshold 0.45 is 0.6730394314822968\n",
            "F1 score at threshold 0.46 is 0.6719216833004895\n",
            "F1 score at threshold 0.47 is 0.6703056768558951\n",
            "F1 score at threshold 0.48 is 0.6667964440983714\n",
            "F1 score at threshold 0.49 is 0.6647887323943661\n",
            "F1 score at threshold 0.5 is 0.6616412087548768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae1lRKOchqz1"
      },
      "source": [
        "The result seems to better than individual pre-trained models and so we let us create a submission file using this model blend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPBVQcichqz1"
      },
      "source": [
        "pred_test_y = 0.33*pred_glove_test_y + 0.33*pred_fasttext_test_y + 0.34*pred_paragram_test_y\n",
        "pred_test_y = (pred_test_y>0.35).astype(int)\n",
        "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
        "out_df['prediction'] = pred_test_y\n",
        "out_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMSwkQdEhqz1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8P5023ihqz1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAPzn_c-hqz2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}